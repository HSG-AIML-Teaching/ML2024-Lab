{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 1000px\" src=\"figures/banner.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"figures/hsg_logo.png\">\n",
    "\n",
    "##  Lab 04- Custom Datasets in PyTorch\n",
    "\n",
    "Machine Learning, University of St. Gallen, Spring Term 2024"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this tutorial, we want to implement a custom PyTorch dataset that processes images of a given dataset folder and prepares inputs for training and evaluation. Although the structure of datasets can significantly for vary, the principles in this tutorial should be applicable to any PyTorch dataset regardless of the folder structure or file formats.\n",
    "\n",
    "Lab Objectives:\n",
    "- Understand dataset structures and how to process dataset files.\n",
    "- Learn how to implement a PyTorch dataset class.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: A Multi-Folder Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we have a dataset called **Omniglot** where the images of each class are inside a separate folder. We want to load the images inside each folder which corrsponds to a separate class and return them as instances of that class. \n",
    "\n",
    "First let's download the files that we need from this link: https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip\n",
    "\n",
    "For more information about the dataset please refer to this link:\n",
    "https://github.com/brendenlake/omniglot/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the file list from a folder we need a package called `glob`. We use pip to install the package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install glob2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how we can retrieve and print the list of folders for a given root directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['character11', 'character16', 'character20', 'character18', 'character19', 'character21', 'character17', 'character10', 'character03', 'character04', 'character05', 'character02', 'character15', 'character12', 'character24', 'character23', 'character22', 'character13', 'character14', 'character09', 'character07', 'character01', 'character06', 'character08']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# glob.glob(\"dataset/Greek/*\")\n",
    "\n",
    "folder_names = [f.split(\"/\")[-1] for f in glob.glob(\"dataset/Greek/*\")]\n",
    "print(folder_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If each folder corresponds to a class, we need to map the class name to a class ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'character01': 0, 'character02': 1, 'character03': 2, 'character04': 3, 'character05': 4, 'character06': 5, 'character07': 6, 'character08': 7, 'character09': 8, 'character10': 9, 'character11': 10, 'character12': 11, 'character13': 12, 'character14': 13, 'character15': 14, 'character16': 15, 'character17': 16, 'character18': 17, 'character19': 18, 'character20': 19, 'character21': 20, 'character22': 21, 'character23': 22, 'character24': 23}\n"
     ]
    }
   ],
   "source": [
    "name_to_id = {name: id for (id, name) in enumerate(sorted(folder_names))}\n",
    "\n",
    "print(name_to_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we extract the list of all images in the dataset and assign them their label IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n"
     ]
    }
   ],
   "source": [
    "all_files = glob.glob(\"./dataset/Greek/*/*.png\")\n",
    "all_label = [name_to_id[path.split(\"/\")[-2]] for path in all_files]\n",
    "\n",
    "print(all_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's define a class that takes care of loading file lists and returning random samples from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE TO BE IMPLEMENTED DURING THE TUTORIAL SESSION\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, root, transform=None) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        folder_names = [f.split(\"/\")[-1] for f in glob.glob(root + \"/*\")]\n",
    "        name_to_id = {name: id for (id, name) in enumerate(sorted(folder_names))}\n",
    "\n",
    "        self.all_paths = glob.glob(root + \"/*/*.png\")\n",
    "        self.all_label = [name_to_id[path.split(\"/\")[-2]] for path in self.all_paths]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.all_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path_i = self.all_paths[index]\n",
    "        image = Image.open(path_i)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = self.all_label[index]\n",
    "\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to test the implemented PyTorch dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transform = transforms.ToTensor()\n",
    "my_dataset = MyDataset(root=\"./dataset/Greek\", transform=my_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]]]),\n",
       " 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset[13]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use the dataset to create a dataloader and iterate through its samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "my_dataloder = DataLoader(my_dataset, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 105, 105])\n",
      "torch.Size([32, 1, 105, 105])\n",
      "torch.Size([32, 1, 105, 105])\n",
      "torch.Size([32, 1, 105, 105])\n",
      "torch.Size([32, 1, 105, 105])\n",
      "torch.Size([32, 1, 105, 105])\n",
      "torch.Size([32, 1, 105, 105])\n",
      "torch.Size([32, 1, 105, 105])\n",
      "torch.Size([32, 1, 105, 105])\n",
      "torch.Size([32, 1, 105, 105])\n",
      "torch.Size([32, 1, 105, 105])\n",
      "torch.Size([32, 1, 105, 105])\n",
      "torch.Size([32, 1, 105, 105])\n",
      "torch.Size([32, 1, 105, 105])\n",
      "torch.Size([32, 1, 105, 105])\n"
     ]
    }
   ],
   "source": [
    "for batch in my_dataloder:\n",
    "    image, label = batch\n",
    "    print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
